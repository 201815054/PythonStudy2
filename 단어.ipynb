{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "단어",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMOyZAVbtvzMF70mezfw8Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/201815054/PythonStudy2/blob/master/%EB%8B%A8%EC%96%B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dvqMOziRZGwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "211fb0be-2d68-4e4a-fe2b-a0bf274cf06a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words=500) #빈도기준으로 500개의 단어들만 포함 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "NayFgrnifc3c"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation, Embedding, SimpleRNN,LSTM\n"
      ],
      "metadata": {
        "id": "9S31T1IlhG78"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape,x_test.shape)\n",
        "# 총 2만5천개의 문장이 들어가있음 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmAfK1eTZJqO",
        "outputId": "a3e15324-eea2-4128-ba90-176c742f2630"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000,) (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train[:2500]\n",
        "x_test = x_test[:2500]\n",
        "y_train= y_train[:2500]\n",
        "y_test = y_test[:2500]"
      ],
      "metadata": {
        "id": "hsqgRm49ncGa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTJqPTzkP-s1",
        "outputId": "fa93b5be-9bea-4272-c68c-e80190d4e458"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[:4] # 단어에 문장을 붙여서 토크나이징 한거.. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auGdV00aZKQW",
        "outputId": "3b74ee2e-375a-45c4-e85f-68dbc8721db2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
              "       list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 2, 8, 118, 2, 14, 394, 20, 13, 119, 2, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 2, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 2, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 2, 7, 2, 2, 349, 2, 148, 2, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 2, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 2, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 2, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 2, 2, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 2, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 2, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 2, 116, 2, 2, 13, 191, 79, 2, 89, 2, 14, 9, 8, 106, 2, 2, 35, 2, 6, 227, 7, 129, 113]),\n",
              "       list([1, 4, 2, 2, 33, 2, 4, 2, 432, 111, 153, 103, 4, 2, 13, 70, 131, 67, 11, 61, 2, 2, 35, 2, 2, 61, 2, 452, 2, 4, 2, 7, 2, 59, 166, 4, 105, 216, 2, 41, 2, 9, 15, 7, 35, 2, 2, 31, 8, 4, 2, 23, 4, 2, 2, 6, 2, 42, 38, 39, 121, 59, 456, 10, 10, 7, 265, 12, 2, 111, 153, 159, 59, 16, 2, 21, 25, 2, 482, 39, 4, 96, 59, 2, 12, 4, 172, 65, 9, 2, 11, 2, 4, 2, 5, 2, 7, 2, 17, 13, 2, 12, 19, 6, 464, 31, 314, 11, 2, 6, 2, 2, 11, 8, 202, 27, 310, 4, 2, 2, 8, 2, 58, 10, 10, 2, 2, 180, 40, 14, 413, 173, 7, 263, 112, 37, 152, 377, 4, 2, 263, 2, 2, 178, 54, 75, 71, 476, 36, 413, 263, 2, 182, 5, 17, 75, 2, 2, 36, 279, 131, 2, 17, 2, 42, 17, 35, 2, 2, 192, 5, 2, 2, 19, 2, 217, 2, 2, 2, 2, 2, 5, 2, 10, 10, 61, 403, 9, 2, 40, 61, 2, 5, 27, 2, 159, 90, 263, 2, 2, 309, 8, 178, 5, 82, 2, 4, 65, 15, 2, 145, 143, 2, 12, 2, 2, 2, 2, 2, 15, 2, 4, 2, 2, 7, 2, 94, 2, 2, 2, 11, 2, 4, 2, 7, 2, 246, 2, 9, 2, 11, 2, 14, 9, 51, 408, 12, 94, 318, 2, 12, 47, 6, 2, 2, 5, 2, 2, 19, 49, 7, 4, 2, 2, 2, 25, 80, 126, 2, 10, 10, 2, 2, 2, 27, 2, 11, 2, 2, 159, 27, 341, 29, 2, 19, 2, 173, 7, 90, 2, 8, 30, 11, 4, 2, 86, 2, 8, 2, 46, 11, 2, 21, 29, 9, 2, 23, 4, 2, 2, 2, 6, 2, 2, 2, 10, 10, 246, 50, 9, 6, 2, 2, 2, 90, 29, 2, 8, 124, 4, 2, 4, 2, 496, 27, 2, 2, 2, 121, 127, 2, 130, 5, 29, 494, 8, 124, 4, 2, 496, 4, 341, 7, 27, 2, 10, 10, 29, 9, 2, 8, 97, 6, 236, 2, 2, 8, 4, 2, 7, 31, 7, 2, 91, 2, 2, 70, 4, 2, 30, 2, 42, 9, 12, 32, 11, 2, 10, 10, 11, 14, 65, 44, 2, 75, 2, 2, 2, 2, 2, 4, 2, 7, 154, 5, 4, 2, 53, 2, 2, 7, 2, 2, 11, 399, 38, 75, 257, 2, 19, 2, 17, 29, 456, 4, 65, 7, 27, 205, 113, 10, 10, 2, 4, 2, 2, 9, 242, 4, 91, 2, 2, 5, 2, 307, 22, 7, 2, 126, 93, 40, 2, 13, 188, 2, 2, 19, 4, 2, 7, 2, 2, 23, 53, 2, 21, 82, 40, 2, 13, 2, 14, 280, 13, 219, 4, 2, 431, 2, 2, 4, 2, 2, 2, 7, 2, 5, 94, 40, 25, 238, 60, 2, 4, 2, 2, 2, 7, 4, 2, 132, 8, 67, 6, 22, 15, 9, 283, 8, 2, 14, 31, 9, 242, 2, 48, 25, 279, 2, 23, 12, 2, 195, 25, 238, 60, 2, 2, 4, 2, 7, 2, 5, 4, 2, 154, 2, 7, 2, 50, 26, 49, 2, 15, 2, 30, 2, 21, 64, 2])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:4] # 긍정과 부정의 라벨이 붙어있음 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2gjSiM9ZKVl",
        "outputId": "5aad7a46-4e94-4ca0-b516-018be757b9e1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length = [len(line) for line in x_train] #문장을 길이를 하나하나 출력해봄"
      ],
      "metadata": {
        "id": "8P66Vs9JZKYG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length "
      ],
      "metadata": {
        "id": "cn1n55ehQ5lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(length,bins=100) #300정도가 많은거같음.  # 히스토그램을 그리기 떄문에 값이 array 값이 다르게 그려짐 "
      ],
      "metadata": {
        "id": "ZtmCP5M2ZKad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "f94c2bd2-f9a8-4d78-d86f-caa7c72e7d5e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  8.,  34.,  79.,  67.,  75., 103., 242., 262., 212., 158., 144.,\n",
              "        117.,  94.,  94.,  70.,  71.,  41.,  49.,  50.,  47.,  37.,  35.,\n",
              "         24.,  21.,  29.,  21.,  28.,  18.,  22.,  16.,  13.,  16.,  20.,\n",
              "         11.,  10.,  10.,   9.,  11.,  18.,  11.,   3.,   7.,   8.,   7.,\n",
              "          6.,   5.,   4.,   8.,   3.,   4.,   5.,   3.,   3.,   2.,   2.,\n",
              "          3.,   5.,   3.,   2.,   2.,   5.,   9.,   1.,   2.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          1.]),\n",
              " array([  16.  ,   32.13,   48.26,   64.39,   80.52,   96.65,  112.78,\n",
              "         128.91,  145.04,  161.17,  177.3 ,  193.43,  209.56,  225.69,\n",
              "         241.82,  257.95,  274.08,  290.21,  306.34,  322.47,  338.6 ,\n",
              "         354.73,  370.86,  386.99,  403.12,  419.25,  435.38,  451.51,\n",
              "         467.64,  483.77,  499.9 ,  516.03,  532.16,  548.29,  564.42,\n",
              "         580.55,  596.68,  612.81,  628.94,  645.07,  661.2 ,  677.33,\n",
              "         693.46,  709.59,  725.72,  741.85,  757.98,  774.11,  790.24,\n",
              "         806.37,  822.5 ,  838.63,  854.76,  870.89,  887.02,  903.15,\n",
              "         919.28,  935.41,  951.54,  967.67,  983.8 ,  999.93, 1016.06,\n",
              "        1032.19, 1048.32, 1064.45, 1080.58, 1096.71, 1112.84, 1128.97,\n",
              "        1145.1 , 1161.23, 1177.36, 1193.49, 1209.62, 1225.75, 1241.88,\n",
              "        1258.01, 1274.14, 1290.27, 1306.4 , 1322.53, 1338.66, 1354.79,\n",
              "        1370.92, 1387.05, 1403.18, 1419.31, 1435.44, 1451.57, 1467.7 ,\n",
              "        1483.83, 1499.96, 1516.09, 1532.22, 1548.35, 1564.48, 1580.61,\n",
              "        1596.74, 1612.87, 1629.  ]),\n",
              " <a list of 100 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# db의 길이가 제각각이면 머신러닝을 할수없어서 길이를 통합시켜줘야함.\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # 길이를 다 일치시킬수있음\n",
        "x_train_seq= pad_sequences(x_train, maxlen=200)  #아까보니 길이가 200~ 300에서 가장 많이 분포되어있어서 200의 길이로 맞춰줌 # np.mean을 쓸 수도 있고 히스토그램으로 많이 분포된걸 확인 할 수도 있고 .. \n",
        "x_test_seq=pad_sequences(x_test,maxlen=200)\n",
        "\n",
        "#padsequence는 긴것도 있고 짧은것도있는데 긴건 짜르고 앞에서 자를수도있고 뒤에서 자를수도있는데 디폴트값으로는 앞에서 자르고 뒤에값을 남기도록 되어있고 짧은문장이있으면 앞에 0을 채워서 길이를 같게해줌 "
      ],
      "metadata": {
        "id": "Q0nXrn_MfcTN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtP4wwm4VCK8",
        "outputId": "7e3d400c-64e3-43bd-c431-46f14ad92a13"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_seq.shape, x_test_seq.shape) #길이 맞춰진것 확인 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHmeZcrKZKcu",
        "outputId": "0b0a58e8-d31f-4b3a-9166-4bb16173d8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2500, 200) (2500, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(SimpleRNN(8, input_shape=(200,1)))\n",
        "model.add(Dense(1,activation='sigmoid')) #긍부정이니까 1, sigmoid\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kUVi8jMZKe9",
        "outputId": "8d32876f-8998-4885-937d-0f0257527370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 8)                 80        \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89\n",
            "Trainable params: 89\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ],
      "metadata": {
        "id": "YDmllWbgZKhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train_seq,y_train, epochs=10, batch_size=64, validation_data=(x_test_seq,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo3ZIyckZKjW",
        "outputId": "31c17b45-58e8-4533-f186-c48d5d730e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "40/40 [==============================] - 13s 271ms/step - loss: 0.9357 - accuracy: 0.4860 - val_loss: 0.8430 - val_accuracy: 0.5308\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 11s 269ms/step - loss: 0.8464 - accuracy: 0.4964 - val_loss: 0.7864 - val_accuracy: 0.5256\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.7935 - accuracy: 0.4968 - val_loss: 0.7518 - val_accuracy: 0.5204\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 11s 267ms/step - loss: 0.7573 - accuracy: 0.4932 - val_loss: 0.7283 - val_accuracy: 0.5184\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.7333 - accuracy: 0.4920 - val_loss: 0.7136 - val_accuracy: 0.5104\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.7159 - accuracy: 0.4920 - val_loss: 0.7031 - val_accuracy: 0.5052\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 18s 460ms/step - loss: 0.6971 - accuracy: 0.5044 - val_loss: 0.6944 - val_accuracy: 0.5028\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 20s 503ms/step - loss: 0.6935 - accuracy: 0.5064 - val_loss: 0.6944 - val_accuracy: 0.5032\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 14s 341ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6941 - val_accuracy: 0.5032\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 12s 306ms/step - loss: 0.6931 - accuracy: 0.4984 - val_loss: 0.6941 - val_accuracy: 0.5040\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f59f725a190>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_seq  #0으로 채운걸 확인 할 수있음.. 정수로되어있는데 저게 사실 단어임(크기를나타내는게아닌 단어기때문에 카테고리화 시켜야함.)\n",
        "# 정수를 넣어줬을때 숫자로 인식해서 문제가있을수있기때문엫그럼.. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82eCPI7oZKll",
        "outputId": "249c0cb4-9ef9-4b87-dde0-9ea23119ad2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  5,  25, 100, ...,  19, 178,  32],\n",
              "       [  0,   0,   0, ...,  16, 145,  95],\n",
              "       [  0,   0,   0, ...,   7, 129, 113],\n",
              "       ...,\n",
              "       [207, 126, 110, ...,  30,   2, 133],\n",
              "       [  2, 123,   6, ...,  95, 106,  15],\n",
              "       [  2,   2,  34, ...,   2, 457, 158]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "x_train_oh = to_categorical(x_train_seq) # 문장들을 원핫으로 바꿈\n",
        "x_test_oh = to_categorical(x_test_seq)"
      ],
      "metadata": {
        "id": "RzZFsUDkmDn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_oh.shape"
      ],
      "metadata": {
        "id": "w1dAoKHZmDs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5b2fe52-707d-4430-bfc7-ccd460f7e968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500, 200, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(500,16,input_length=200)) #원핫을하면 500차원으로 바뀌는데 200x500으로바껴서 그런식으로 바꾸지 않고 Embedding레이어를 주면 500단어가있고 16차원의 벡터로 바꾸라는것.. 시퀀스는200으로 설정해줬고\n",
        "model.add(LSTM(8))\n",
        "model.add(Dense(1,activation='sigmoid')) #긍부정이니까 1, sigmoid\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "RMfI1HCsmDuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc42781c-732b-45f4-8db9-8efb4c243d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 16)           8000      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 8)                 800       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,809\n",
            "Trainable params: 8,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ],
      "metadata": {
        "id": "KH0yzHH2mD-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train_seq.astype(float),y_train, epochs=10, batch_size=64, validation_data=(x_test_seq.astype(float),y_test))\n",
        "#그냥 정수형태로 입력해주면 임베딩을 통해서 500차원의 원핫이아니라 16차원으로 줄어들어서 학습도 빨리됨."
      ],
      "metadata": {
        "id": "jGvMgBNvmEA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de169558-26d5-4da8-c8ee-0e73fcbf8f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "40/40 [==============================] - 7s 62ms/step - loss: 0.6919 - accuracy: 0.5196 - val_loss: 0.6920 - val_accuracy: 0.4948\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 0.6862 - accuracy: 0.5524 - val_loss: 0.6852 - val_accuracy: 0.5332\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.6564 - accuracy: 0.6436 - val_loss: 0.6318 - val_accuracy: 0.6104\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 0.5769 - accuracy: 0.7368 - val_loss: 0.5680 - val_accuracy: 0.7568\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.5395 - accuracy: 0.7660 - val_loss: 0.5650 - val_accuracy: 0.7452\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.5243 - accuracy: 0.7804 - val_loss: 0.5454 - val_accuracy: 0.7640\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.4822 - accuracy: 0.8044 - val_loss: 0.5287 - val_accuracy: 0.7708\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.4757 - accuracy: 0.7948 - val_loss: 0.5333 - val_accuracy: 0.7412\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.4461 - accuracy: 0.8184 - val_loss: 0.5201 - val_accuracy: 0.7516\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.4487 - accuracy: 0.8068 - val_loss: 0.5156 - val_accuracy: 0.7488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QCSL_GBCmEC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_IzQmK2bmEFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-rOfNWcwmEHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hkDkvDghZKn9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}