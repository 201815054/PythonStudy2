{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44708f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류모델 종류 - Logistic Regression,SGD,KNN,SVM,Decision Tree, Random Forest, LGBMClassifier\n",
    "# 최적화 - lgbm ,smote(imbalanced), outlier제거, scaler,randomsearch\n",
    "# 평가지표 - classification_report, f1_score, roc_auc_score(predic_proba)\n",
    "\n",
    "# 모델을 만들 data 를 merge. \n",
    "# 라벨값을 바이너리로 만들어줌 \n",
    "# 트레인 테스트 데이터셋을 분리 \n",
    "# 모델을 만들 반복문 돌리기\n",
    "# 최적화하고 모델 다시 만들어서 차이를 비교 \n",
    "# 피쳐임포턴스를 확인한 후에 피쳐를 뽑아내서 다시 반복 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fdbceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 여러개 데이터프레임 merge 하기\n",
    "\n",
    "# from functools import reduce\n",
    "# import pandas as pd\n",
    "# dfs = [df_coldwave, df_kr, df_near]\n",
    "# cold_kr_near = reduce(lambda left, right: pd.merge(left,right,left_index=True, right_index=True), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89bb9e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Feature importance 시각화 하기 \n",
    "\n",
    "# model =[rfc, dtc, lgbm]\n",
    "# for i in model:\n",
    "#     # 배열형태로 반환\n",
    "#     ft_importance_values = i.feature_importances_\n",
    "\n",
    "# # 정렬과 시각화를 쉽게 하기 위해 series 전환\n",
    "#     ft_series = pd.Series(ft_importance_values, index = x_train.columns)\n",
    "#     ft_top20 = ft_series.sort_values(ascending=False)[:20]\n",
    "\n",
    "# # 시각화\n",
    "#     plt.figure(figsize=(8,6))\n",
    "#     plt.title('{} Feature Importance Top 20'.format(i))\n",
    "#     sns.barplot(x=ft_top20, y=ft_top20.index)\n",
    "#     plt.show()\n",
    "#     print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e50bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 랜덤포레스트 모델의 하이퍼파라미터를 랜덤서치로 최적의 값 찾기 .\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import randint\n",
    "\n",
    "# est = RandomForestClassifier(n_jobs=-1, n_estimators=500)\n",
    "# rf_p_dist = {'max_depth':[3,5,10,None],\n",
    "#                 'n_estimators':[100,200,300,400,500],\n",
    "#                 'max_features':randint(1,3),\n",
    "#                 'criterion':['gini','entropy'],\n",
    "#                 'bootstrap':['True','False'],\n",
    "#                 'min_samples_leaf':randint(1,4)}\n",
    "\n",
    "# def hypertuning_rscv(est,p_distr, nbr_iter,x,y):\n",
    "#     rdmserch = RandomizedSearchCV(est,param_distributions=p_distr,\n",
    "#                                  n_jobs=-1, n_iter=nbr_iter, cv=9)\n",
    "    \n",
    "#     rdmserch.fit(x,y)\n",
    "#     ht_params = rdmserch.best_params_\n",
    "#     ht_score = rdmserch.best_score_\n",
    "#     return ht_params, ht_score\n",
    "\n",
    "# rf_parameters,rf_ht_score = hypertuning_rscv(est,rf_p_dist,40,x,y)\n",
    "\n",
    "# y_pred = rfc.predict(x_test)\n",
    "\n",
    "# # classifier=RandomForestClassifier\n",
    "\n",
    "# # 교차검증하기 \n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# cross_val = cross_val_score(rfc,x,y,cv=10,scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b0dd0",
   "metadata": {},
   "source": [
    "#### 전처리와 모델링할때 쓸 모듈 import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3af0b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager, rc\n",
    "font_path = \"C:/Windows/Fonts/NGULIM.TTF\"\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font)\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from functools import reduce\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 분류모델 import \n",
    "# Logistic Regression,SGD,KNN,SVM,Decision Tree, Random Forest, LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report,roc_auc_score,f1_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "svm = SVC(probability=True)\n",
    "dtc = DecisionTreeClassifier()\n",
    "rfc = RandomForestClassifier()\n",
    "lgbm = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795a1c3b",
   "metadata": {},
   "source": [
    "#### train, validation, test 데이터 분리하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e02cdcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "열대야 = pd.read_csv('./data/ML_preprocessed/열대야.csv',encoding='cp949',index_col=0)\n",
    "고층기후 = pd.read_csv('./data/ML_preprocessed/고층기후.csv',encoding='cp949',index_col=0)\n",
    "주변국기후 = pd.read_csv('./data/ML_preprocessed/주변국기후.csv',encoding='cp949',index_col=0)\n",
    "폭염 = pd.read_csv('./data/ML_preprocessed/폭염.csv',encoding='cp949',index_col=0)\n",
    "한국기후 = pd.read_csv('./data/ML_preprocessed/한국기후.csv',encoding='cp949',index_col=0)\n",
    "한파 = pd.read_csv('./data/ML_preprocessed/한파.csv',encoding='cp949',index_col=0)\n",
    "해상기후 = pd.read_csv('./data/ML_preprocessed/해상기후.csv',encoding='cp949',index_col=0)\n",
    "\n",
    "# 데이터를 나누기 위해 인덱스를 일시로 해줌 \n",
    "열대야.set_index('일시',inplace=True)\n",
    "주변국기후.set_index('일시',inplace=True)\n",
    "폭염.set_index('일시',inplace=True)\n",
    "한국기후.set_index('일시',inplace=True)\n",
    "한파.set_index('일시',inplace=True)\n",
    "해상기후.set_index('일시',inplace=True)\n",
    "\n",
    "# test 할 데이터 \n",
    "열대야2019 = 열대야.loc['2019-01-01':'2019-12-31']\n",
    "한파2019 = 한파.loc['2019-01-01':'2019-12-31']\n",
    "폭염2019 = 폭염.loc['2019-01-01':'2019-12-31']\n",
    "주변국기후2019 = 주변국기후.loc['2019-01-01':'2019-12-31']\n",
    "한국기후2019 = 한국기후.loc['2019-01-01':'2019-12-31']\n",
    "해상기후2019 = 해상기후.loc['2019-01-01':'2019-12-31']\n",
    "고층기후2019 = 고층기후.loc['2019-01-01':'2019-12-31']\n",
    "\n",
    "#train,validation 할 데이터 \n",
    "열대야2019drop = 열대야.drop(열대야2019.index,axis=0)\n",
    "한파2019drop = 한파.drop(한파2019.index,axis=0)\n",
    "폭염2019drop = 폭염.drop(폭염2019.index,axis=0)\n",
    "주변국기후2019drop = 주변국기후.drop(주변국기후2019.index,axis=0)\n",
    "한국기후2019drop = 한국기후.drop(한국기후2019.index,axis=0)\n",
    "해상기후2019drop = 해상기후.drop(해상기후2019.index,axis=0)\n",
    "고층기후2019drop = 고층기후.drop(고층기후2019.index,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ecdf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "931dc65a",
   "metadata": {},
   "source": [
    "#### 열대야 + 한국기후 조합 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "479afde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "\n",
    "# 일시 컬럼으로 merge 하기 위해 일시로 설정된 index를 다시 reset해줌 (근데 merge할때 index로 합치면 되는데 굳이;)\n",
    "열대야2019drop = 열대야2019drop.reset_index()\n",
    "한국기후2019drop = 한국기후2019drop.reset_index()\n",
    "\n",
    "# 일시컬럼을 기준으로 한국기후 날짜에 merge (한국기후는 1990년, 열대야는 1973부터 시작.)\n",
    "trop_kr = pd.merge(열대야2019drop,한국기후2019drop,on='일시',how='right')\n",
    "\n",
    "# 서로 겹치지 않는 날짜를 제거하기위해 index를 일시로 설정하고, loc를 사용하여 겹치지 않는 날짜 제거 \n",
    "trop_kr=trop_kr.set_index('일시')\n",
    "trop_kr=trop_kr.drop(trop_kr.loc['2021-09-01':'2021-12-31'].index)\n",
    "\n",
    "# 타겟값을 바이너리로 만들어줌 \n",
    "trop_kr['재난일어난날'] = trop_kr['재난일어난날'].fillna(0)\n",
    "trop_kr['재난일어난날'] = trop_kr['재난일어난날'].apply(lambda x: x if str(x) == '0' else '1')\n",
    "\n",
    "# 타겟날짜를 2주뒤로 shift 해줌 \n",
    "trop_kr['재난일어난날'] = trop_kr['재난일어난날'].shift(periods=14, axis=0)\n",
    "\n",
    "# 2주뒤로 shift 한만큼 생긴 nan값을 제거해줌 \n",
    "trop_kr.dropna(inplace=True)\n",
    "\n",
    "# 재난일어난날 컬럼이 object로 되어있으니 뉴메릭으로 바꿔줌\n",
    "trop_kr['재난일어난날'] = trop_kr['재난일어난날'].astype(int)\n",
    "\n",
    "# 모델링 할 데이터준비완료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57daaad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d48f978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      2009\n",
      "           1       0.60      0.42      0.49       229\n",
      "\n",
      "    accuracy                           0.91      2238\n",
      "   macro avg       0.77      0.69      0.72      2238\n",
      "weighted avg       0.90      0.91      0.91      2238\n",
      "\n",
      "roc_auc_score : 0.9402209706973641\n",
      "--------------------------------------------------\n",
      "DecisionTreeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      2009\n",
      "           1       0.52      0.52      0.52       229\n",
      "\n",
      "    accuracy                           0.90      2238\n",
      "   macro avg       0.73      0.73      0.73      2238\n",
      "weighted avg       0.90      0.90      0.90      2238\n",
      "\n",
      "roc_auc_score : 0.7326974031704491\n",
      "--------------------------------------------------\n",
      "LGBMClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      2009\n",
      "           1       0.73      0.60      0.66       229\n",
      "\n",
      "    accuracy                           0.94      2238\n",
      "   macro avg       0.84      0.79      0.81      2238\n",
      "weighted avg       0.93      0.94      0.93      2238\n",
      "\n",
      "roc_auc_score : 0.9659610356018007\n",
      "--------------------------------------------------\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      2009\n",
      "           1       0.69      0.46      0.55       229\n",
      "\n",
      "    accuracy                           0.92      2238\n",
      "   macro avg       0.82      0.72      0.75      2238\n",
      "weighted avg       0.91      0.92      0.92      2238\n",
      "\n",
      "roc_auc_score : 0.9557417385955341\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 열대야 + 한국기후 조합 데이터 모델링 #\n",
    "\n",
    "# x,y 설정\n",
    "y = trop_kr.재난일어난날\n",
    "x = trop_kr.drop('재난일어난날',axis=1)\n",
    "\n",
    "# 트레인 테스트 셋 분리 \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "\n",
    "# 분류 모델 돌리기 \n",
    "models = [lr,dtc,lgbm,rfc,svm,knn]\n",
    "\n",
    "for i in models:\n",
    "    i.fit(x_train,y_train)\n",
    "    pred = i.predict(x_test)\n",
    "    proba = i.predict_proba(x_test)[:,1]\n",
    "    \n",
    "    print(i.__class__.__name__)\n",
    "    print(classification_report(y_test,pred))\n",
    "    print('roc_auc_score :',roc_auc_score(y_test,proba))\n",
    "    print('-'*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7dd465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 하기 \n",
    "\n",
    "# x_train, x_test스케일링 \n",
    "# 임밸런스한 데이터 smote \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote =SMOTE(random_state=0)\n",
    "x_train_sm, y_train_sm =smote.fit_resample(x_train_scaled,y_train)\n",
    "\n",
    "# 최적화한 데이터로 분류 모델 돌리기 \n",
    "models = [lr,dtc,lgbm,rfc,svm,knn]\n",
    "\n",
    "for i in models:\n",
    "    i.fit(x_train_sm,y_train_sm)\n",
    "    pred = i.predict(x_test_scaled)\n",
    "    proba = i.predict_proba(x_test_scaled)[:,1]\n",
    "    \n",
    "    print(i.__class__.__name__)\n",
    "    print(classification_report(y_test,pred))\n",
    "    print('roc_auc_score :',roc_auc_score(y_test,proba))\n",
    "    print('-'*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Feature importance 시각화 하기 \n",
    "\n",
    "model = [dtc,lgbm,rfc]\n",
    "for i in model:\n",
    "    # 배열형태로 반환\n",
    "    ft_importance_values = i.feature_importances_\n",
    "\n",
    "# 정렬과 시각화를 쉽게 하기 위해 series 전환\n",
    "    ft_series = pd.Series(ft_importance_values, index = x_train.columns)\n",
    "    ft_top20 = ft_series.sort_values(ascending=False)[:20]\n",
    "\n",
    "# 시각화\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.title('{} Feature Importance Top 20'.format(i))\n",
    "    sns.barplot(x=ft_top20, y=ft_top20.index)\n",
    "    plt.show()\n",
    "    print('-'*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ac63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### feature importance로 확인한 feature를 뽑아서 rfc와 lgbm 돌려보기 \n",
    "# rfc의 feature_importance\n",
    "ft_importance_values =rfc.feature_importances_\n",
    "ft_series = pd.Series(ft_importance_values, index = x_train.columns)\n",
    "ft_top20 = ft_series.sort_values(ascending=False)[:20]\n",
    "\n",
    "ft_top20 # 탑20피쳐임포턴스확인\n",
    "\n",
    "trop_kr_rfc = trop_kr.loc[:,['재난일어난날','제주최저기온',     '제주평균기온',     '전주최저기온',        '광주평균 증기압',     \n",
    "                       '광주최저기온','대구평균 증기압','청주평균 이슬점온도','청주평균기온',\n",
    "                            '대구평균 이슬점온도',   '서울평균기온' ,      '광주평균기온',       '제주평균 이슬점온도',    \n",
    "                            '청주최저기온'   ,    '전주평균 증기압',   '전주평균기온',        \n",
    "                            '서울평균 증기압',   '제주평균 증기압',     '서울최저기온'   ,    '춘천평균 증기압',     \n",
    "                            '청주평균 증기압']]\n",
    "\n",
    "rfc_y = trop_kr_rfc['재난일어난날']\n",
    "rfc_x = trop_kr_rfc.drop('재난일어난날',axis=1)\n",
    "\n",
    "rfc_x_train,rfc_x_test,rfc_y_train,rfc_y_test=train_test_split(rfc_x,rfc_y,test_size=0.2,random_state=0)\n",
    "# 최적화 하기전 돌려보기\n",
    "rfc.fit(rfc_x_train,rfc_y_train)\n",
    "pred = rfc.predict(rfc_x_test)\n",
    "proba = rfc.predict_proba(rfc_x_test)[:,1]\n",
    "    \n",
    "print(classification_report(rfc_y_test,pred))\n",
    "print('roc_auc_score :',roc_auc_score(rfc_y_test,proba))\n",
    "print('-'*50)\n",
    "\n",
    "# 최적화하기\n",
    "scaler.fit(rfc_x_train)\n",
    "rfc_x_train_scaled = scaler.transform(rfc_x_train)\n",
    "rfc_x_test_scaled = scaler.transform(rfc_x_test)\n",
    "\n",
    "smote =SMOTE(random_state=0)\n",
    "rfc_x_train_sm, rfc_y_train_sm =smote.fit_resample(rfc_x_train_scaled,rfc_y_train)\n",
    "# 분류 모델 돌리기 \n",
    "\n",
    "rfc.fit(rfc_x_train_sm,rfc_y_train_sm)\n",
    "pred = rfc.predict(rfc_x_test_scaled)\n",
    "proba = rfc.predict_proba(rfc_x_test_scaled)[:,1]\n",
    "    \n",
    "print(classification_report(rfc_y_test,pred))\n",
    "print('roc_auc_score :',roc_auc_score(rfc_y_test,proba))\n",
    "print('-'*50)\n",
    "\n",
    "# lgbm feature importance 모델 돌려보기 \n",
    "# lgbm의 feature_importance\n",
    "ft_importance_values =lgbm.feature_importances_\n",
    "ft_series = pd.Series(ft_importance_values, index = x_train.columns)\n",
    "ft_top20 = ft_series.sort_values(ascending=False)[:20]\n",
    "\n",
    "ft_top20\n",
    "\n",
    "trop_kr_lgbm = trop_kr.loc[:,['재난일어난날','제주최저기온',           '강릉최대 풍향',          '전주최대 풍향',           \n",
    "'대구최대 풍향',           '서울최대 풍향',           \n",
    "'제주평균 상대습도',         '광주최대 풍속 풍향',        '강릉최대 풍속 풍향',        '광주최대 순간 풍속 풍향',     '제주1시간 최다강수량',       \n",
    "'춘천최대 풍향',           '춘천최대 풍속 풍향',        '제주최대 풍향',           '강릉평균 중하층운량',        '대구최대 순간 풍속 풍향',     \n",
    "'청주평균 중하층운량',        '서울최대 순간 풍속 풍향',     '제주최대 순간 풍속 풍향',     '청주최대 풍향',           '광주최대 풍향']]\n",
    "\n",
    "lgbm_y = trop_kr_lgbm['재난일어난날']\n",
    "lgbm_x = trop_kr_lgbm.drop('재난일어난날',axis=1)\n",
    "\n",
    "lgbm_x_train,lgbm_x_test,lgbm_y_train,lgbm_y_test=train_test_split(lgbm_x,lgbm_y,test_size=0.2,random_state=0)\n",
    "# 최적화 하기전 돌려보기\n",
    "lgbm.fit(lgbm_x_train,lgbm_y_train)\n",
    "pred = lgbm.predict(lgbm_x_test)\n",
    "proba = lgbm.predict_proba(lgbm_x_test)[:,1]\n",
    "    \n",
    "print(classification_report(lgbm_y_test,pred))\n",
    "print('roc_auc_score :',roc_auc_score(lgbm_y_test,proba))\n",
    "print('-'*50)\n",
    "    \n",
    "#최적화하기\n",
    "scaler.fit(rfc_x_train)\n",
    "lgbm_x_train_scaled = scaler.transform(lgbm_x_train)\n",
    "lgbm_x_test_scaled = scaler.transform(lgbm_x_test)\n",
    "\n",
    "smote =SMOTE(random_state=0)\n",
    "lgbm_x_train_sm, lgbm_y_train_sm =smote.fit_resample(lgbm_x_train_scaled,lgbm_y_train)\n",
    "# 분류 모델 돌리기 \n",
    "\n",
    "lgbm.fit(lgbm_x_train_sm,lgbm_y_train_sm)\n",
    "pred = lgbm.predict(lgbm_x_test_scaled)\n",
    "proba = lgbm.predict_proba(lgbm_x_test_scaled)[:,1]\n",
    "    \n",
    "print(classification_report(lgbm_y_test,pred))\n",
    "print('roc_auc_score :',roc_auc_score(lgbm_y_test,proba))\n",
    "print('-'*50)\n",
    "    \n",
    "#rfc랑 lgbm제일 높게나옴 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacfa867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d964a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02096dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7feefdd",
   "metadata": {},
   "source": [
    "#### 열대야 + 한국기후 + 주변국기후 + 해상기후 + 고층기후 조합 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab04ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든기후와 열대야 합치기 reduce ㅅㅂ 어케쓰는지몰라\n",
    "trop_dfs = pd.merge(열대야2019drop,한국기후2019drop,on='일시',how='right')\n",
    "trop_dfs = pd.merge(trop_dfs,주변국기후2019drop,on='일시',how='right')\n",
    "trop_dfs = pd.merge(trop_dfs,해상기후2019drop,on='일시',how='left')\n",
    "trop_dfs = pd.merge(trop_dfs,고층기후2019drop,on='일시',how='left')\n",
    "\n",
    "# 타겟값을 바이너리로 ! \n",
    "trop_dfs['재난일어난날'] = trop_dfs['재난일어난날'].fillna(0)\n",
    "trop_dfs['재난일어난날'] = trop_dfs['재난일어난날'].apply(lambda x: x if str(x) == '0' else '1')\n",
    "\n",
    "# 타겟날짜를 2주뒤로 shift 해줌 \n",
    "trop_dfs['재난일어난날'] = trop_dfs['재난일어난날'].shift(periods=14, axis=0)\n",
    "\n",
    "# 2주뒤로 shift 한만큼 생긴 nan값을 제거해줌 \n",
    "trop_dfs.dropna(inplace=True)\n",
    "\n",
    "# 재난일어난날 컬럼이 object로 되어있으니 뉴메릭으로 바꿔줌\n",
    "trop_dfs['재난일어난날'] = trop_dfs['재난일어난날'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b25a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 돌리기 \n",
    "\n",
    "# x,y 설정\n",
    "y = trop_dfs.재난일어난날\n",
    "x = trop_dfs.drop('재난일어난날',axis=1)\n",
    "\n",
    "# 트레인 테스트 셋 분리 \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "\n",
    "# 분류 모델 돌리기 \n",
    "models = [lr,dtc,lgbm,rfc,svm,knn]\n",
    "\n",
    "for i in models:\n",
    "    i.fit(x_train,y_train)\n",
    "    pred = i.predict(x_test)\n",
    "    proba = i.predict_proba(x_test)[:,1]\n",
    "    \n",
    "    print(i.__class__.__name__)\n",
    "    print(classification_report(y_test,pred))\n",
    "    print('roc_auc_score :',roc_auc_score(y_test,proba))\n",
    "    print('-'*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 하기 \n",
    "\n",
    "# x_train, x_test스케일링 \n",
    "# 임밸런스한 데이터 smote \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote =SMOTE(random_state=0)\n",
    "x_train_sm, y_train_sm =smote.fit_resample(x_train_scaled,y_train)\n",
    "\n",
    "# 최적화한 데이터로 분류 모델 돌리기 \n",
    "models = [lr,dtc,lgbm,rfc,svm,knn]\n",
    "\n",
    "for i in models:\n",
    "    i.fit(x_train_sm,y_train_sm)\n",
    "    pred = i.predict(x_test_scaled)\n",
    "    proba = i.predict_proba(x_test_scaled)[:,1]\n",
    "    \n",
    "    print(i.__class__.__name__)\n",
    "    print(classification_report(y_test,pred))\n",
    "    print('roc_auc_score :',roc_auc_score(y_test,proba))\n",
    "    print('-'*50)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ba6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Feature importance 시각화 하기 \n",
    "\n",
    "model = [dtc,lgbm,rfc]\n",
    "for i in model:\n",
    "    # 배열형태로 반환\n",
    "    ft_importance_values = i.feature_importances_\n",
    "\n",
    "# 정렬과 시각화를 쉽게 하기 위해 series 전환\n",
    "    ft_series = pd.Series(ft_importance_values, index = x_train.columns)\n",
    "    ft_top20 = ft_series.sort_values(ascending=False)[:20]\n",
    "\n",
    "# 시각화\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.title('{} Feature Importance Top 20'.format(i))\n",
    "    sns.barplot(x=ft_top20, y=ft_top20.index)\n",
    "    plt.show()\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48af777",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 모든기후와 한파 조합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2227ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든기후와 한파 합치기 reduce ㅅㅂ 어케쓰는지몰라\n",
    "coldwave_dfs = pd.merge(한파2019drop,한국기후2019drop,on='일시',how='right')\n",
    "coldwave_dfs = pd.merge(coldwave_dfs,주변국기후2019drop,on='일시',how='right')\n",
    "coldwave_dfs = pd.merge(coldwave_dfs,해상기후2019drop,on='일시',how='left')\n",
    "coldwave_dfs = pd.merge(coldwave_dfs,고층기후2019drop,on='일시',how='left')\n",
    "\n",
    "# 타겟값을 바이너리로 ! \n",
    "coldwave_dfs['재난일어난날'] = coldwave_dfs['재난일어난날'].fillna(0)\n",
    "coldwave_dfs['재난일어난날'] = coldwave_dfs['재난일어난날'].apply(lambda x: x if str(x) == '0' else '1')\n",
    "\n",
    "# 타겟날짜를 2주뒤로 shift 해줌 \n",
    "coldwave_dfs['재난일어난날'] = coldwave_dfs['재난일어난날'].shift(periods=14, axis=0)\n",
    "\n",
    "# 2주뒤로 shift 한만큼 생긴 nan값을 제거해줌 \n",
    "coldwave_dfs.dropna(inplace=True)\n",
    "\n",
    "# 재난일어난날 컬럼이 object로 되어있으니 뉴메릭으로 바꿔줌\n",
    "coldwave_dfs['재난일어난날'] = coldwave_dfs['재난일어난날'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee2a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 돌리기 \n",
    "\n",
    "# x,y 설정\n",
    "y = coldwave_dfs.재난일어난날\n",
    "x = coldwave_dfs.drop('재난일어난날',axis=1)\n",
    "\n",
    "# 트레인 테스트 셋 분리 \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "\n",
    "# 분류 모델 돌리기 \n",
    "models = [lr,dtc,lgbm,rfc,svm,knn]\n",
    "\n",
    "for i in models:\n",
    "    i.fit(x_train,y_train)\n",
    "    pred = i.predict(x_test)\n",
    "    proba = i.predict_proba(x_test)[:,1]\n",
    "    \n",
    "    print(i.__class__.__name__)\n",
    "    print(classification_report(y_test,pred))\n",
    "    print('roc_auc_score :',roc_auc_score(y_test,proba))\n",
    "    print('-'*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8077bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 하기 \n",
    "\n",
    "# x_train, x_test스케일링 \n",
    "# 임밸런스한 데이터 smote \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote =SMOTE(random_state=0)\n",
    "x_train_sm, y_train_sm =smote.fit_resample(x_train_scaled,y_train)\n",
    "\n",
    "# 최적화한 데이터로 분류 모델 돌리기 \n",
    "models = [lr,dtc,lgbm,rfc,svm,knn]\n",
    "\n",
    "for i in models:\n",
    "    i.fit(x_train_sm,y_train_sm)\n",
    "    pred = i.predict(x_test_scaled)\n",
    "    proba = i.predict_proba(x_test_scaled)[:,1]\n",
    "    \n",
    "    print(i.__class__.__name__)\n",
    "    print(classification_report(y_test,pred))\n",
    "    print('roc_auc_score :',roc_auc_score(y_test,proba))\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a0f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Feature importance 시각화 하기 \n",
    "\n",
    "model = [dtc,lgbm,rfc]\n",
    "for i in model:\n",
    "    # 배열형태로 반환\n",
    "    ft_importance_values = i.feature_importances_\n",
    "\n",
    "# 정렬과 시각화를 쉽게 하기 위해 series 전환\n",
    "    ft_series = pd.Series(ft_importance_values, index = x_train.columns)\n",
    "    ft_top20 = ft_series.sort_values(ascending=False)[:20]\n",
    "\n",
    "# 시각화\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.title('{} Feature Importance Top 20'.format(i))\n",
    "    sns.barplot(x=ft_top20, y=ft_top20.index)\n",
    "    plt.show()\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b3f421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b512a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5744d47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c5ee53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3172f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf48590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df78e0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067131e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aafc3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6ddc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baa3f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d48a289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f7ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb62e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15cd26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb2a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf62eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d3a986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb95e8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be88e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4b074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412bf177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbae3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187cdccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2418e474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05d447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6e5d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e13638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c37953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7840a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b22d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825aae42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6d7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c719c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c78b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea349ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
